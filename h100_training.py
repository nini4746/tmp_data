# -*- coding: utf-8 -*-
"""
ê³ ê¸‰ í•™ìŠµ ëª¨ë‹ˆí„°ë§ ë„êµ¬ë“¤ (ì„ íƒì‚¬í•­)
ë©”ì¸ ì½”ë“œì— ì¶”ê°€í•˜ê±°ë‚˜ ë³„ë„ë¡œ ì‚¬ìš© ê°€ëŠ¥
"""

import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import clear_output
import wandb  # pip install wandb
import time
import threading
import os

# -------------------------------
# 1) ì‹¤ì‹œê°„ ê·¸ë˜í”„ í”Œë¡¯ (Jupyter/Colabìš©)
# -------------------------------
class RealTimePlotter:
    def __init__(self):
        plt.ion()  # ëŒ€í™”í˜• ëª¨ë“œ ì¼œê¸°
        self.fig, self.axes = plt.subplots(2, 2, figsize=(15, 10))
        self.fig.suptitle('Real-time Training Monitor', fontsize=16)
        
    def update_plots(self, train_losses, train_accs, val_losses, val_accs, 
                    epoch_times, best_val_acc, current_epoch):
        clear_output(wait=True)
        
        epochs = list(range(len(train_losses)))
        
        # Loss ê·¸ë˜í”„
        self.axes[0,0].clear()
        self.axes[0,0].plot(epochs, train_losses, 'b-', label='Train Loss', alpha=0.7)
        self.axes[0,0].plot(epochs, val_losses, 'r-', label='Val Loss', alpha=0.7)
        self.axes[0,0].set_title('Loss Over Time')
        self.axes[0,0].set_xlabel('Epoch')
        self.axes[0,0].set_ylabel('Loss')
        self.axes[0,0].legend()
        self.axes[0,0].grid(True, alpha=0.3)
        
        # Accuracy ê·¸ë˜í”„
        self.axes[0,1].clear()
        self.axes[0,1].plot(epochs, train_accs, 'b-', label='Train Acc', alpha=0.7)
        self.axes[0,1].plot(epochs, val_accs, 'r-', label='Val Acc', alpha=0.7)
        self.axes[0,1].axhline(y=best_val_acc, color='g', linestyle='--', 
                              label=f'Best Val: {best_val_acc:.2f}%')
        self.axes[0,1].set_title('Accuracy Over Time')
        self.axes[0,1].set_xlabel('Epoch')
        self.axes[0,1].set_ylabel('Accuracy (%)')
        self.axes[0,1].legend()
        self.axes[0,1].grid(True, alpha=0.3)
        
        # ì—í¬í¬ë³„ ì‹œê°„
        self.axes[1,0].clear()
        self.axes[1,0].plot(epochs, epoch_times, 'g-', alpha=0.7)
        if len(epoch_times) > 10:
            moving_avg = np.convolve(epoch_times, np.ones(10)/10, mode='valid')
            self.axes[1,0].plot(epochs[9:], moving_avg, 'orange', linewidth=2, 
                              label='Moving Average (10)')
            self.axes[1,0].legend()
        self.axes[1,0].set_title('Training Speed')
        self.axes[1,0].set_xlabel('Epoch')
        self.axes[1,0].set_ylabel('Time per Epoch (s)')
        self.axes[1,0].grid(True, alpha=0.3)
        
        # í•™ìŠµë¥ 
        self.axes[1,1].clear()
        if hasattr(self, 'learning_rates'):
            self.axes[1,1].semilogy(epochs, self.learning_rates, 'purple', alpha=0.7)
            self.axes[1,1].set_title('Learning Rate Schedule')
            self.axes[1,1].set_xlabel('Epoch')
            self.axes[1,1].set_ylabel('Learning Rate')
            self.axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# -------------------------------
# 2) Weights & Biases ì—°ë™ (ê³ ê¸‰ ì‹¤í—˜ ì¶”ì )
# -------------------------------
def setup_wandb(project_name="indoor_positioning", experiment_name=None):
    """
    W&B ì„¤ì • - í´ë¼ìš°ë“œì—ì„œ ì‹¤í—˜ ì¶”ì 
    ì‚¬ìš©ë²•: wandb login í›„ ì´ í•¨ìˆ˜ í˜¸ì¶œ
    """
    config = {
        "batch_size": BATCH_SIZE,
        "learning_rate": LEARNING_RATE,
        "hidden_sizes": HIDDEN_SIZES,
        "dropout": DROPOUT,
        "weight_decay": WEIGHT_DECAY,
        "max_epochs": MAX_EPOCHS,
        "architecture": "MLP",
        "dataset_size": len(train_loader.dataset)
    }
    
    wandb.init(
        project=project_name,
        name=experiment_name,
        config=config
    )
    return wandb

def log_to_wandb(epoch, train_loss, train_acc, val_loss, val_acc, 
                learning_rate, epoch_time):
    """W&Bì— ë©”íŠ¸ë¦­ ë¡œê¹…"""
    wandb.log({
        "epoch": epoch,
        "train/loss": train_loss,
        "train/accuracy": train_acc,
        "val/loss": val_loss,
        "val/accuracy": val_acc,
        "learning_rate": learning_rate,
        "epoch_time": epoch_time
    })

# -------------------------------
# 3) í…”ë ˆê·¸ë¨ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
# -------------------------------
def send_telegram_notification(message, bot_token=None, chat_id=None):
    """
    í…”ë ˆê·¸ë¨ìœ¼ë¡œ í•™ìŠµ ì§„í–‰ ìƒí™© ì•Œë¦¼
    ë´‡ í† í°ê³¼ ì±„íŒ… ID í•„ìš”
    """
    if not bot_token or not chat_id:
        return
        
    try:
        import requests
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        data = {
            "chat_id": chat_id,
            "text": message,
            "parse_mode": "HTML"
        }
        requests.post(url, data=data, timeout=10)
    except:
        pass  # ì‹¤íŒ¨í•´ë„ í•™ìŠµì€ ê³„ì†

# -------------------------------
# 4) í–¥ìƒëœ í•™ìŠµ ë£¨í”„ (ìœ„ ê¸°ëŠ¥ë“¤ í†µí•©)
# -------------------------------
def enhanced_training_loop(model, train_loader, val_loader, criterion, optimizer, 
                          scheduler, device, max_epochs=200, patience=25,
                          use_wandb=False, use_telegram=False, use_plots=False,
                          telegram_config=None):
    """
    ëª¨ë“  ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì´ í†µí•©ëœ í•™ìŠµ ë£¨í”„
    """
    
    # ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì´ˆê¸°í™”
    plotter = RealTimePlotter() if use_plots else None
    
    if use_wandb:
        wandb_run = setup_wandb()
    
    # í•™ìŠµ ë³€ìˆ˜ë“¤
    best_val_acc = 0.0
    patience_counter = 0
    train_losses, train_accs = [], []
    val_losses, val_accs = [], []
    learning_rates = []
    epoch_times = []
    improvement_epochs = []
    
    start_time = time.time()
    
    # ì‹œì‘ ì•Œë¦¼
    if use_telegram and telegram_config:
        send_telegram_notification(
            f"ğŸš€ <b>Training Started</b>\n"
            f"Model: MLP ({sum(p.numel() for p in model.parameters()):,} params)\n"
            f"Dataset: {len(train_loader.dataset):,} samples\n"
            f"Max Epochs: {max_epochs}",
            **telegram_config
        )
    
    print(f"{'Epoch':>5} | {'Train Loss':>10} {'Train Acc':>10} | {'Val Loss':>8} {'Val Acc':>8} | {'LR':>8} | {'Time':>6} | {'Best':>6}")
    print("-" * 85)
    
    for epoch in range(max_epochs):
        epoch_start = time.time()
        
        # í•™ìŠµ & ê²€ì¦
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step(val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        
        # ì‹œê°„ ê¸°ë¡
        epoch_time = time.time() - epoch_start
        epoch_times.append(epoch_time)
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        learning_rates.append(current_lr)
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì²´í¬
        improved = val_acc > best_val_acc
        if improved:
            best_val_acc = val_acc
            patience_counter = 0
            improvement_epochs.append(epoch)
            
            # ëª¨ë¸ ì €ì¥
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'best_val_acc': best_val_acc,
                # ... ë‹¤ë¥¸ ì •ë³´ë“¤
            }, "best_model.pth")
            
        else:
            patience_counter += 1
        
        # W&B ë¡œê¹…
        if use_wandb:
            log_to_wandb(epoch, train_loss, train_acc, val_loss, val_acc, 
                        current_lr, epoch_time)
        
        # ì‹¤ì‹œê°„ í”Œë¡¯ ì—…ë°ì´íŠ¸
        if use_plots and plotter and (epoch % 5 == 0 or improved):
            plotter.learning_rates = learning_rates
            plotter.update_plots(train_losses, train_accs, val_losses, val_accs,
                               epoch_times, best_val_acc, epoch)
        
        # ì½˜ì†” ì¶œë ¥
        show_epoch = (epoch < 20 or epoch % 5 == 0 or improved or epoch == max_epochs-1)
        if show_epoch:
            status = "ğŸ¯ NEW!" if improved else ""
            print(f"{epoch:5d} | {train_loss:10.4f} {train_acc:9.2f}% | "
                  f"{val_loss:8.4f} {val_acc:7.2f}% | {current_lr:8.2e} | "
                  f"{epoch_time:5.1f}s | {best_val_acc:5.2f}% {status}")
        
        # ì¤‘ìš”í•œ ì´ì •í‘œì—ì„œ í…”ë ˆê·¸ë¨ ì•Œë¦¼
        if use_telegram and telegram_config:
            should_notify = (
                improved and val_acc > 85.0 or  # ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±
                epoch % 100 == 0 or  # 100ì—í¬í¬ë§ˆë‹¤
                patience_counter == patience // 2  # ì ˆë°˜ patience ë„ë‹¬
            )
            
            if should_notify:
                elapsed = time.time() - start_time
                send_telegram_notification(
                    f"ğŸ“Š <b>Training Update</b> (Epoch {epoch})\n"
                    f"Val Accuracy: {val_acc:.2f}% {'ğŸ¯' if improved else ''}\n"
                    f"Best So Far: {best_val_acc:.2f}%\n"
                    f"Elapsed: {elapsed/60:.1f}min\n"
                    f"Patience: {patience_counter}/{patience}",
                    **telegram_config
                )
        
        # ì¡°ê¸° ì¢…ë£Œ
        if patience_counter >= patience:
            break
    
    # ìµœì¢… ì•Œë¦¼
    training_time = time.time() - start_time
    if use_telegram and telegram_config:
        send_telegram_notification(
            f"âœ… <b>Training Completed!</b>\n"
            f"Best Accuracy: {best_val_acc:.2f}%\n"
            f"Total Time: {training_time/60:.1f}min\n"
            f"Epochs: {len(train_losses)}",
            **telegram_config
        )
    
    return {
        'train_losses': train_losses,
        'train_accs': train_accs,
        'val_losses': val_losses,
        'val_accs': val_accs,
        'best_val_acc': best_val_acc,
        'training_time': training_time
    }

# -------------------------------
# ì‚¬ìš© ì˜ˆì‹œ
# -------------------------------
"""
# ê¸°ë³¸ ì‚¬ìš©ë²• (ë©”ì¸ ì½”ë“œì—ì„œ)
results = enhanced_training_loop(
    model, train_loader, val_loader, criterion, optimizer, scheduler, device,
    max_epochs=200, patience=25
)

# W&B ì‚¬ìš© ì‹œ
results = enhanced_training_loop(
    model, train_loader, val_loader, criterion, optimizer, scheduler, device,
    use_wandb=True
)

# í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‚¬ìš© ì‹œ
telegram_config = {
    'bot_token': 'YOUR_BOT_TOKEN',
    'chat_id': 'YOUR_CHAT_ID'
}
results = enhanced_training_loop(
    model, train_loader, val_loader, criterion, optimizer, scheduler, device,
    use_telegram=True, telegram_config=telegram_config
)

# ì‹¤ì‹œê°„ í”Œë¡¯ ì‚¬ìš© ì‹œ (Jupyter/Colab)
results = enhanced_training_loop(
    model, train_loader, val_loader, criterion, optimizer, scheduler, device,
    use_plots=True
)
"""