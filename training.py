# -*- coding: utf-8 -*-
"""
training_data2.csv (ì•/ë’¤, ê³ ì •ìì„¸)ë¡œ ì‹¤ë‚´ ìœ„ì¹˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ/í‰ê°€/ì €ì¥
- ìº˜ë¦¬ë¸Œë ˆì´ì…˜(í•˜ë“œ/ì†Œí”„íŠ¸ ì•„ì´ì–¸) ë‹¨ê³„ëŠ” ìƒëµ
- íŠ¹ì§•: B ì„±ë¶„, |B|, |B_xy|, ë‹¨ìœ„ë²¡í„°, ê°ë„(sin/cos)
- ì¶œë ¥: mlp_position.pkl, label_encoder.pkl, metrics.json
"""

import json
import joblib
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# -------------------------------
# 0) ì„¤ì •
# -------------------------------
CSV_PATH = "training_data2.csv"     # ê°™ì€ í´ë”ë©´ íŒŒì¼ëª…ë§Œ
LABEL_COL = "Position"              # ë¼ë²¨ ì»¬ëŸ¼ëª… (í•„ìš”ì‹œ ë°”ê¾¸ì„¸ìš”)
MAG_COLS = ["Mag_X", "Mag_Y", "Mag_Z"]
ORI_COLS = ["Ori_X", "Ori_Y", "Ori_Z"]  # deg ê°€ì •. ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë‘ì„¸ìš”: ORI_COLS=[]
TEST_SIZE = 0.2
RANDOM_STATE = 42
STANDARDIZE = True                  # í‘œì¤€í™” ON/OFF
DEROTATE_MODE = "none"              # "none" | "yaw_only" | "full"  (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ìœ¼ë‹ˆ ê¸°ë³¸ none ê¶Œì¥)

MODEL_PKL = "mlp_position.pkl"
LE_PKL    = "label_encoder.pkl"
METRICS_JSON = "metrics.json"

# -------------------------------
# 1) ìœ í‹¸
# -------------------------------
def _rot_x(a):
    ca, sa = np.cos(a), np.sin(a)
    return np.array([[1,0,0],[0,ca,-sa],[0,sa,ca]])

def _rot_y(b):
    cb, sb = np.cos(b), np.sin(b)
    return np.array([[cb,0,sb],[0,1,0],[-sb,0,cb]])

def _rot_z(g):
    cg, sg = np.cos(g), np.sin(g)
    return np.array([[cg,-sg,0],[sg,cg,0],[0,0,1]])

def euler_zyx_to_R(roll, pitch, yaw):
    # R = Rz(yaw) @ Ry(pitch) @ Rx(roll)
    return _rot_z(yaw) @ _rot_y(pitch) @ _rot_x(roll)

def derotate(B, df, mode="none"):
    if mode == "none" or len(ORI_COLS)==0:
        return B
    roll = np.deg2rad(df[ORI_COLS[0]].values.astype(float))
    pitch= np.deg2rad(df[ORI_COLS[1]].values.astype(float))
    yaw  = np.deg2rad(df[ORI_COLS[2]].values.astype(float))
    out = np.zeros_like(B)
    if mode == "yaw_only":
        for i in range(B.shape[0]):
            out[i] = _rot_z(yaw[i]) @ B[i]
        return out
    if mode == "full":
        for i in range(B.shape[0]):
            out[i] = euler_zyx_to_R(roll[i], pitch[i], yaw[i]) @ B[i]
        return out
    return B

def build_features(df):
    # B ì„±ë¶„
    B = df[MAG_COLS].values.astype(float)

    # (ì„ íƒ) ë””ë¡œí…Œì´ì…˜ - ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ì´ ì“°ëŠ” ê±´ ê³¼êµì • ìœ„í—˜ì´ ìˆì–´ ê¸°ë³¸ ë”
    Bc = derotate(B, df, DEROTATE_MODE)

    # í¬ê¸°/ë°©í–¥ íŠ¹ì„±
    B_mag = np.linalg.norm(Bc, axis=1, keepdims=True)           # |B|
    B_xy  = np.linalg.norm(Bc[:, :2], axis=1, keepdims=True)    # |B_xy|
    eps = 1e-9
    B_unit = Bc / (B_mag + eps)                                 # ë‹¨ìœ„ë²¡í„°

    feat = pd.DataFrame(index=df.index)
    feat["B_x"] = Bc[:,0]; feat["B_y"] = Bc[:,1]; feat["B_z"] = Bc[:,2]
    feat["B_mag"] = B_mag[:,0]
    feat["B_xy_mag"] = B_xy[:,0]
    feat["Bux"] = B_unit[:,0]; feat["Buy"] = B_unit[:,1]; feat["Buz"] = B_unit[:,2]

    # ê°ë„ â†’ sin/cos (ìˆì„ ë•Œë§Œ)
    for a in ORI_COLS:
        rad = np.deg2rad(df[a].values.astype(float))
        feat[f"{a}_sin"] = np.sin(rad)
        feat[f"{a}_cos"] = np.cos(rad)

    return feat

# -------------------------------
# 2) ë°ì´í„° ë¡œë“œ & ë¶„í• 
# -------------------------------
df = pd.read_csv(CSV_PATH)
need_cols = set([LABEL_COL] + MAG_COLS + ORI_COLS)
missing = [c for c in need_cols if c not in df.columns]
if missing:
    raise ValueError(f"CSVì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

X_raw = df[MAG_COLS + ORI_COLS]
y_raw = df[LABEL_COL].values

X_tr_df, X_te_df, y_tr_raw, y_te_raw = train_test_split(
    X_raw, y_raw, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_raw
)

# -------------------------------
# 3) í”¼ì²˜ ìƒì„± + ìŠ¤ì¼€ì¼ëŸ¬
# -------------------------------
feat_tr = build_features(X_tr_df)
feat_te = build_features(X_te_df)

scaler = None
if STANDARDIZE:
    scaler = StandardScaler().fit(feat_tr.values)
    feat_tr.iloc[:, :] = scaler.transform(feat_tr.values)
    feat_te.iloc[:, :] = scaler.transform(feat_te.values)

X_tr = feat_tr.values
X_te = feat_te.values

# ë¼ë²¨ ì¸ì½”ë”©
le = LabelEncoder()
y_tr = le.fit_transform(y_tr_raw)
y_te = le.transform(y_te_raw)

# -------------------------------
# 4) ëª¨ë¸ ì •ì˜/í•™ìŠµ (MLP)
# -------------------------------
mlp = MLPClassifier(
    hidden_layer_sizes=(256, 128),
    activation="relu",
    solver="adam",
    alpha=1e-4,
    batch_size=128,
    learning_rate_init=1e-3,
    max_iter=250,
    early_stopping=True,
    validation_fraction=0.15,
    n_iter_no_change=15,
    random_state=RANDOM_STATE,
    verbose=False
)

print("ğŸš€ Training MLP ...")
mlp.fit(X_tr, y_tr)
print("âœ… Train done. epochs:", len(getattr(mlp, "loss_curve_", [])))

# -------------------------------
# 5) í‰ê°€ (MLP)
# -------------------------------
y_tr_pred = mlp.predict(X_tr)
y_te_pred = mlp.predict(X_te)

acc_tr = accuracy_score(y_tr, y_tr_pred)
acc_te = accuracy_score(y_te, y_te_pred)
print(f"ğŸ“Š MLP Accuracy - train: {acc_tr:.4f} | test: {acc_te:.4f}")

class_names = [str(c) for c in le.classes_]
label_order = np.arange(len(le.classes_))

report = classification_report(
    y_te, y_te_pred,
    labels=label_order,
    target_names=class_names,
    digits=4,
    zero_division=0
)
cm = confusion_matrix(y_te, y_te_pred, labels=label_order)

print("\nğŸ“„ Classification Report (MLP, test)")
print(report)
print("ğŸ”¢ Confusion Matrix (MLP, test)")
print(cm)

# -------------------------------
# 6) ë¹„êµìš© ë² ì´ìŠ¤ë¼ì¸ (ì €ì¥ì€ ì•ˆ í•¨)
# -------------------------------
knn = KNeighborsClassifier(n_neighbors=1, metric="cosine")
knn.fit(X_tr, y_tr)
y_te_knn = knn.predict(X_te)
acc_knn = accuracy_score(y_te, y_te_knn)
print(f"\nğŸ§ª 1-NN(cosine) baseline test acc: {acc_knn:.4f}")

# -------------------------------
# 7) ì €ì¥
# -------------------------------
joblib.dump(mlp, MODEL_PKL)
joblib.dump(le, LE_PKL)

if 'scaler' in globals() and scaler is not None:
    joblib.dump(scaler, "scaler.pkl")

metrics = {
    "train_accuracy": float(acc_tr),
    "test_accuracy": float(acc_te),
    "classes": class_names,
    "confusion_matrix": cm.tolist(),
    "classification_report_text": report,
    "loss_curve": [float(v) for v in getattr(mlp, "loss_curve_", [])],
    "features_used": list(feat_tr.columns),
    "standardized": STANDARDIZE,
    "derotate_mode": DEROTATE_MODE
}
with open(METRICS_JSON, "w", encoding="utf-8") as f:
    json.dump(metrics, f, ensure_ascii=False, indent=2)

print(f"\nğŸ’¾ Saved: {MODEL_PKL}, {LE_PKL}, {METRICS_JSON}")
print("ğŸ¯ All done.")
